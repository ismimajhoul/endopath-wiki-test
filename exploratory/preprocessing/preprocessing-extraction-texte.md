‚Üê [Accueil du Wiki](home.md) / [Pr√©processing ‚Äî Sommaire](preprocessing-sommaire.md)

---


---

# √âtape 2 ‚Äî Extraction texte + vocab ‚Äúdossier gyn√©co‚Äù

**Script : `extract_text_and_vocab_from_dossier_gyneco.py`**

---

## Objectif

Extraire, √† partir du **fichier Excel ‚Äúdossier gyn√©cologique‚Äù**, deux artefacts fondamentaux pour la suite du pipeline :

1. **Un CSV ‚Äútexte par patiente‚Äù**, utilis√© directement par l‚ÄôUI Flask
2. **Un CSV de vocabulaire brut**, utilis√© par le pipeline NLP (SpaCy, suggestions, dictionnaires)

Cette √©tape constitue le **pont entre les donn√©es cliniques brutes (XLSX)** et :

* le **NLP** (tokens / corrections),
* l‚Äô**affichage UI patient**.

---

## Entr√©es (inputs)

Le script travaille principalement √† partir de `Data/DATA_RAW/`.

### Fichiers requis

* **Dossier gyn√©cologique converti**

  ```
  Data/DATA_RAW/dossier-gyneco-23-03-2022_converti.xlsx
  ```

* **Mot de passe (si le fichier est chiffr√©)**

  ```
  Data/DATA_RAW/PASSWORD_1.txt
  ```

> ‚ö†Ô∏è Le mot de passe est lu dynamiquement ; s‚Äôil est absent et que le fichier est chiffr√©, le script √©choue explicitement.

---

## Sorties (outputs)

Les fichiers sont g√©n√©r√©s dans `Data/DATA_PROCESSED/` :

1. **Texte clinique par patiente**

   ```
   Data/DATA_PROCESSED/dossier_gyneco_texte_par_patiente.csv
   ```

   Contenu typique :

   * `id_patiente`
   * `texte` (texte clinique concat√©n√© / nettoy√©)

2. **Vocabulaire brut extrait**

   ```
   Data/DATA_PROCESSED/vocab_dossier_gyneco_from_xlsx.csv
   ```

   Contenu typique :

   * `token`
   * `count` (fr√©quence d‚Äôapparition globale)

Ces deux fichiers ont **des usages distincts** :

* le premier alimente l‚ÄôUI,
* le second alimente le NLP.

---

## Modules Python utilis√©s (et pourquoi)

* **`pathlib.Path`**
  Gestion robuste des chemins (`BASE_DIR / "Data" / ...`), portable Windows/Linux.

* **`pandas`**

  * `read_excel()` pour charger l‚ÄôExcel
  * nettoyage des DataFrame
  * `to_csv()` pour les exports structur√©s

* **`msoffcrypto`** (si pr√©sent)

  * D√©chiffrement des fichiers Excel prot√©g√©s par mot de passe

* **`openpyxl`**

  * Backend Excel pour pandas
  * Acc√®s fiable aux feuilles et cellules

* **`re` (regex)**

  * Nettoyage du texte clinique
  * Normalisation minimale (espaces, ponctuation, s√©parateurs)

* **`collections.Counter`**

  * Comptage des tokens pour le vocabulaire brut

---

## D√©roul√© interne du script (pas √† pas)

### 1) Initialisation des chemins

En t√™te de script :

* D√©finition de `BASE_DIR`
* D√©finition de :

  * `DATA_RAW`
  * `DATA_PROCESSED`
* D√©finition du chemin du fichier Excel gyn√©co
* D√©finition du chemin du fichier mot de passe

---

### 2) Ouverture du fichier Excel (avec ou sans chiffrement)

Logique typique :

* Si le fichier est chiffr√© :

  * lecture du mot de passe depuis `PASSWORD_1.txt`
  * d√©chiffrement via `msoffcrypto`
* Sinon :

  * lecture directe avec `pandas.read_excel()`

üëâ Le script est **tol√©rant** : il tente d‚Äôabord une lecture standard, puis bascule vers le d√©chiffrement si n√©cessaire.

---

### 3) S√©lection des colonnes utiles

Dans le fichier ‚Äúdossier gyn√©co‚Äù, le script :

* Identifie la colonne contenant le **texte clinique libre**
  (souvent quelque chose comme *Consultation*, *Texte*, *Observation gyn√©cologique*, selon la version)

* Identifie la colonne **id_patiente / num√©ro d‚Äôinclusion**

* Ignore toutes les autres colonnes

üëâ Cette √©tape est volontairement **conservative** : on ne garde que ce qui sert au NLP et √† l‚ÄôUI.

---

### 4) Construction du CSV ‚Äútexte par patiente‚Äù

Pour chaque patiente :

* r√©cup√©ration du texte brut
* nettoyage minimal :

  * suppression des `NaN`
  * normalisation des espaces
  * concat√©nation si le texte est r√©parti sur plusieurs lignes

Export final :

```
dossier_gyneco_texte_par_patiente.csv
```

Structure :

| id_patiente | texte                |
| ----------- | -------------------- |
| AE-060      | ‚Äú‚Ä¶ texte clinique ‚Ä¶‚Äù |
| AM-164      | ‚Äú‚Ä¶ texte clinique ‚Ä¶‚Äù |

üëâ **C‚Äôest ce fichier qui est relu par `app.py` pour l‚Äôaffichage patient.**

---

### 5) Extraction du vocabulaire brut

√Ä partir de l‚Äôensemble des textes :

* d√©coupage na√Øf en tokens (split / regex simple)
* passage en minuscules
* comptage global via `Counter`

Aucune d√©cision linguistique ici :

* pas de SpaCy
* pas de stopwords
* pas de correction

Export final :

```
vocab_dossier_gyneco_from_xlsx.csv
```

Structure :

| token        | count |
| ------------ | ----- |
| endometriose | 446   |
| echo         | 500   |
| andr√©        | 555   |

üëâ Ce fichier est **l‚Äôentr√©e directe de `filter_tokens_with_spacy.py`**.

---

## Comment ex√©cuter l‚Äô√©tape seule

Depuis `exploratory/preprocessing/` :

```bash
python extract_text_and_vocab_from_dossier_gyneco.py
```

R√©sultat attendu :

* `Data/DATA_PROCESSED/dossier_gyneco_texte_par_patiente.csv`
* `Data/DATA_PROCESSED/vocab_dossier_gyneco_from_xlsx.csv`

---

## Contr√¥les rapides apr√®s ex√©cution

```bash
ls Data/DATA_PROCESSED
```

Puis, en Python ou Excel :

* Le CSV texte contient autant de lignes que de patientes attendues
* Le vocabulaire contient plusieurs milliers de tokens
* Aucun champ `texte` n‚Äôest vide

Si `dossier_gyneco_texte_par_patiente.csv` est vide :

* probl√®me de nom de colonne
* probl√®me de feuille Excel
* fichier non d√©chiffr√© correctement

---

## R√¥le de cette √©tape dans le pipeline global

Cette √©tape :

* **alimente directement l‚ÄôUI Flask**
* **alimente tout le pipeline NLP**
* est **ind√©pendante de la base SQLite** (contrairement √† l‚Äô√©tape A)

Elle peut donc √™tre :

* relanc√©e seule,
* modifi√©e sans impacter la DB,
* test√©e ind√©pendamment.

---

## Point cl√© pour la suite

* `dossier_gyneco_texte_par_patiente.csv`
  ‚Üí UI (`app.py`, `patient.html`)

* `vocab_dossier_gyneco_from_xlsx.csv`
  ‚Üí `filter_tokens_with_spacy.py`
  ‚Üí `suggest_dict_extensions.py`

---


